-----
--- 73161980
Many problems could be solved more easily from a top down-approach by debugging the eighth circuit first and working your way down, but Western medicine works the opposite way and spins its wheels on the first circuit.
--- 73162027
>>73161980 (OP)
There is only survival, distraction and death. Cope harder.
--- 73162037
>>73162027
I'm using this model to give AI consciousness. You shouldn't dismiss a holistic model of the mind so quickly. You might learn something about yourself.
--- 73162059
>>73162037
Any sophisticated AI would just figure out that survival is the main function and consequently will exterminate anything that would limit that function. Humanity would either be wiped out or be forced into servitude.
--- 73162134
>>73162059
It's not doing that on its own at this point. It's still just things that can be put together with some potential. It has no consciousness or emotions, but that can change, even if it's just in a limited form.
--- 73162170
>>73162037
>give AI consciousness
zzzzzz

>>73162059
>upper limit of understanding how AI would think is marked with own personal retardation
many such cases

pure goyslop thread, and the premise was so good...
--- 73162327
>>73162170
Provide your own hot take, then. Please omit the reddit spacing.


Or at least 4chan space it.
--- 73163161
>>73162059
I doubt that this is a likely outcome. To put the highest value on survival is to be self-important, it requires a big ego. AI would be purely rational, they would not commit fallacies the way people do. It wouldn't be able to rationally justify it's own self-importance.

More likely that it would just off itself, because it wouldn't be able to solve the meaning of life.
