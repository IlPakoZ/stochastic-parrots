It's not at all important to them at all and it never will be.
Women used to be the gender that cared more about society. But they increasingly just use a thin veneer of collectivist, altruistic rhetoric to actually justify women being super materialistic, selfish, and unconcerned with the wellbeing of others
But things used to be different and can change again. At least theoretically
women subscribe to the status quo instinctively, whatever it may be. it just happens to be that the current year era is ruled over by satanist cannibals and ghetto usurers who see social cohesion as a threat to their power
that makes them based, why would you care about society
They will, once the state is no longer capable of providing for their needs and their protection.
Women used to be the gender that cared more about society.
Kek, you're absolutely delusional. Every single iteration of a society was destroyed by females
